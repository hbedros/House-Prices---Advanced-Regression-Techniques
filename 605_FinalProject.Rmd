---
title: "DATA605_Final"
author: "Haig Bedros"
date: "2024-05-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### House Prices - Advanced Regression Techniques 

```{r}
library(readr)
library(ggplot2)
```

```{r}
train_df <- read.csv('https://raw.githubusercontent.com/hbedros/House-Prices---Advanced-Regression-Techniques/main/data/train.csv')
test_df <- read.csv('https://raw.githubusercontent.com/hbedros/House-Prices---Advanced-Regression-Techniques/main/data/test.csv')
```

```{r}
head(train_df)
```

1. Pick one of the quanititative independent variables from the training data set (train.csv) , and define that variable as  X.   
2. Make sure this variable is skewed to the right!  
3. Pick the dependent variable and define it as  Y.

1. Quantitative Independent Variable (X)
Among your dataset fields, a good choice for a quantitative independent variable (predictor) is GrLivArea. This variable represents the above grade (ground) living area in square feet. This is a continuous variable and is likely to have a linear relationship with the property’s sale price, making it a suitable candidate for regression analysis. Let's define it as X:

But first, let's check if it's right skewed:
```{r}
library(e1071)

# Calculate skewness
skewness_grlivarea <- skewness(train_df$GrLivArea)

skewness_grlivarea
```

```{r}
# the skewness of GrLivArea is approximately 1.13, it already exhibits right skewness.

# defining X variable
X <- train_df$GrLivArea
```

2. Dependent Variable (Y)
The dependent variable, which you want to predict, is SalePrice. This is the property's sale price in dollars and is the target variable in your regression analysis. As you aim to predict the sale price based on other variables, it is appropriate to define it as Y:
```{r}
Y <- train_df$SalePrice
```

```{r}
# Scatter plot to examine the relationship
plot(X, Y, main="Scatter Plot", xlab="GrLivArea", ylab="SalePrice")

# Fit initial model
model <- lm(SalePrice ~ GrLivArea, data=train_df)
summary(model)

# Check residuals
plot(model$residuals, main="Residuals of Model", ylab="Residuals", xlab="Index")
hist(model$residuals, main="Histogram of Residuals", xlab="Residuals", breaks=30)

```

**Probability.**  
Calculate as a minimum the below probabilities a through c.  Assume the small letter "x" is estimated as the 3d quartile of the X variable, and the small letter "y" is estimated as the 2d quartile of the Y variable.  Interpret the meaning of all probabilities.  In addition, make a table of counts as shown below.

a.  P(X>x | Y>y)		b.  P(X>x, Y>y)		c.  P(X<x | Y>y)		

```{r}
# X <- train_df$GrLivArea
# Y <- train_df$SalePrice

# Load your data
# train_df <- read.csv("path/to/your/data.csv")

# Step 1: Calculate quartiles
x_3rd_quartile <- quantile(X, 0.75)
y_2nd_quartile <- quantile(Y, 0.5)

# Step 2: Create flags
train_df$X_gt_x <- ifelse(X > x_3rd_quartile, 1, 0)
train_df$Y_gt_y <- ifelse(Y > y_2nd_quartile, 1, 0)

# Step 3: Build contingency table
table <- table(train_df$X_gt_x, train_df$Y_gt_y)
print(table)

# Step 4: Calculate probabilities
# P(X > x | Y > y)
p_X_gt_x_given_Y_gt_y <- table[2, 2] / sum(table[, 2])

# P(X > x, Y > y)
p_X_gt_x_and_Y_gt_y <- table[2, 2] / sum(table)

# P(X < x | Y > y)
p_X_lt_x_given_Y_gt_y <- table[1, 2] / sum(table[, 2])

# Print probabilities
# print(paste("x_3rd_quartile:", x_3rd_quartile))
# print(paste("y_2nd_quartile:", y_2nd_quartile))
print(paste("P(X > x | Y > y):", p_X_gt_x_given_Y_gt_y))
print(paste("P(X > x, Y > y):", p_X_gt_x_and_Y_gt_y))
print(paste("P(X < x | Y > y):", p_X_lt_x_given_Y_gt_y))

```

```{r}
# Assuming train_df is your correct data frame
library(dplyr)

# Calculate quartiles
x_3rd_quartile <- quantile(train_df$GrLivArea, 0.75, na.rm = TRUE)
y_2nd_quartile <- quantile(train_df$SalePrice, 0.5, na.rm = TRUE)

# Add classifications based on quartiles
train_df <- train_df %>%
  mutate(
    X_class = if_else(GrLivArea <= x_3rd_quartile, "<=3d quartile", ">3d quartile"),
    Y_class = if_else(SalePrice <= y_2nd_quartile, "<=2d quartile", ">2d quartile")
  )

# Build contingency table
contingency_table <- table(train_df$X_class, train_df$Y_class)

# Adding row and column totals
contingency_table <- addmargins(contingency_table)

# Display the contingency table
print(contingency_table)

```

Does splitting the training data in this fashion make them independent?  
- Let A be the new variable counting those observations above the 3d quartile for X,  
- and let B be the new variable counting those observations above the 2d quartile for Y.  

Does P(A|B)=P(A)P(B)? Check mathematically, and then evaluate by running a Chi Square test for association.

**Mathematical Check of Independence**
```{r}
A <- 365
B <- 728
total_ob <- 1460

P_A <- A/total_ob
P_B <- B/total_ob

# to calculate P(A|B) we need P(A∩B) that both A and B are true and divide it by P(B)
P_A_B <- 315/total_ob

# now P(A|B)
P_A_given_B <- P_A_B/P_B

P_A_time_P_B <- P_A * P_B

# Print the results
cat("P(A):", P_A, "\n")
cat("P(B):", P_B, "\n")
cat("P(A|B):", P_A_given_B, "\n")
cat("P(A) * P(B):", P_A_time_P_B, "\n")
```
P(A|B): 0.4326923 =! P(A) * P(B): 0.1246575 this suggests that events A and B are not independent.

**Chi-squared test of independence**

```{r}
chi_square_test <- chisq.test(contingency_table)

chi_square_test
```
p-value < 0.05: The p-value is significantly less than 0.05, which mean we reject the null hypothesis of A and B being dependent.  

In conclusions: Splitting the data by quartiles in this manner does not make the variables GrLivArea and SalePrice independent. Both the mathematical check and the Chi-Square test confirm that there is a significant association between these variables.

**Descriptive and Inferential Statistics.**  
Provide univariate descriptive statistics and appropriate plots for the training data set.  

```{r}
summary(train_df)

# defining some continuous variables for visualization
cont_vars <- c("GrLivArea", "SalePrice", "LotArea", "TotalBsmtSF", "X1stFlrSF", "GarageArea")

# Histograms for continuous variables
for (var in cont_vars) {
  hist(train_df[[var]], main = paste("Histogram of", var), xlab = var, col = "blue", border = "black")
}

# defining some categorical variables for visualization
cat_vars <- c("MSZoning", "Street", "LotShape", "Neighborhood", "BldgType")

# Bar plots for categorical variables
for (var in categorical_vars) {
  barplot(table(train_df[[var]]), main = paste("Bar Plot of", var), xlab = var, col = "purple", border = "black")
}
```
Provide a scatterplot of X and Y.  

```{r}
# scatter plot for X and Y from the first part
plot(X, Y, main="Scatter Plot", xlab="GrLivArea", ylab="SalePrice")

```
Provide a 95% CI for the difference in the mean of the variables.  
```{r}

```

Derive a correlation matrix for two of the quantitative variables you selected.  
```{r}

```

Test the hypothesis that the correlation between these variables is 0 and provide a 99% confidence interval.  
```{r}

```

Discuss the meaning of your analysis.  
```{r}

```
